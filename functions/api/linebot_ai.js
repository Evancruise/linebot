import express from "express";
import * as line from "@line/bot-sdk";
import { getOpenAI } from "./openAIClient.js";
import { loadMemory, appendMemory, upsertVectorMemory, queryVectorMemory } from "./memoryService.js";
import { getLineConfig } from "./lineConfig.js";
import { extractLongTermMemory } from "./memoryExtractor.js";

// import OpenAI from "openai";
import admin from "firebase-admin";
import { embedText } from "./embeddings.js";

// const MEMORY_COLLECTION = "line_memory";
// const VECTOR_ROOT = "linebot_memory_vectors";

const router = express.Router();
let db = null;
const appName = `app-${process.env.FIRESTORE_DATABASE_ID}`;

if (!admin.apps.length) {
    admin.initializeApp(
        {
            projectId: process.env.GCLOUD_PROJECT_ID,
        },
        // appName
    );

    db = admin.firestore();
}

router.get("/", (req, res) => {
    res.send("æˆ‘æ˜¯ linebot_ai webhook");
});

// const memory_linebot_ai = {} //å¯¦ä½œè¨˜æ†¶åŠŸèƒ½
// const MAX_MEMORY_LENGTH = 20; // æ¯å€‹å°è©±æœ€å¤šä¿ç•™ 20 è¼ªï¼ˆ10 çµ„å•ç­”ï¼‰

router.post(
    "/",
    (req, res, next) => {
        const config = getLineConfig();
        return line.middleware(config)(req, res, next);
    },
    async (req, res) => {
        res.sendStatus(200);

        console.log("Firestore project:", admin.app().options.projectId);

        const config = getLineConfig();
        const client = new line.messagingApi.MessagingApiClient(config);
        const openai = getOpenAI();

        const events = req.body.events || [];
        for (const event of events) {
            if (event.type !== "message" || event.message.type !== "text")
                continue;

            const userMessage = event.message.text.trim();
            const conversationId = getConversationId(event.source);

            if (!conversationId) continue;

            try {
                // çŸ­æœŸè¨˜æ†¶
                const memory = await loadMemory(conversationId, db);

                // å‘é‡æª¢ç´¢
                let hits = [];
                
                try {
                    const qEmb = await embedText(userMessage);
                    hits = await queryVectorMemory(conversationId, qEmb, 5);
                } catch (e) {
                    console.warn("RAG disabled for this turn:", e.message);
                }

                const ragContext = hits
                    .filter(h => h.score > 0.25)
                    .map((h, i) => `[è¨˜æ†¶${i + 1}|ç›¸ä¼¼åº¦${h.score.toFixed(2)}] ${h.text}`)
                    .join("\n");
                
                const system = `ä½ æ˜¯å‹å–„ã€å¹½é»˜ã€ä½¿ç”¨ç¹é«”ä¸­æ–‡çš„ LINE åŠ©æ‰‹ã€‚
                ä½ æœƒåƒè€ƒã€Œæª¢ç´¢åˆ°çš„è¨˜æ†¶ã€ä¾†å›ç­”ï¼Œä½†è‹¥è¨˜æ†¶ä¸è¶³æˆ–ä¸ç›¸é—œï¼Œå°±ä»¥ä½¿ç”¨è€…ç•¶ä¸‹è¨Šæ¯ç‚ºä¸»ã€‚
                `;
                
                const messages = [
                    { role: "system", content: system },
                    ...(ragContext
                        ? [{ role: "system", content: `ä»¥ä¸‹æ˜¯æª¢ç´¢åˆ°çš„è¨˜æ†¶ (å¯èƒ½æœ‰ç”¨):\n${ragContext}`}]
                        : []),
                    ...memory,
                    { role: "user", content: userMessage },
                ];
                
                // å‘¼å«æ¨¡å‹
                const response = await openai.responses.create({
                    model: "gpt-4o-mini",
                    input: messages,
                    temperature: 0.7,
                    max_output_tokens: 800,
                });

                const aiText = response.output_text || "æˆ‘å‰›å‰›æƒ³äº†ä¸€ä¸‹ï¼Œä½†æœ‰é»å¡ä½"; 
                
                // å¯«å›çŸ­æœŸè¨˜æ†¶
                await appendMemory(conversationId, db, "user", userMessage);
                await appendMemory(conversationId, db, "assistant", aiText);

                // å¯«å›å‘é‡è¨˜æ†¶
                /*
                if (shouldStoreToLongTerm(userMessage)) {
                    await upsertVectorMemory(conversationId, {
                        text: userMessage,
                        embedding: qEmb,
                        meta: { type: "user_fact_candidate" },
                    });
                }
                */
                
                const memoryDecision = await extractLongTermMemory(userMessage);

                if (memoryDecision.store && memoryDecision.confidence >= 0.6) {
                    const emb = await embedText(memoryDecision.text);
                
                    await upsertVectorMemory(
                        conversationId, 
                        db,
                        {
                            text: memoryDecision.text,
                            embedding: emb,
                            meta: {
                                type: memoryDecision.type,
                                confidence: memoryDecision.confidence,
                                source: "llm_extractor",
                            },
                        }
                    );
                }
                
                // å›è¦† LINE
                await client.replyMessage({
                    replyToken: event.replyToken,
                    messages: [{ type: "text", text: aiText }],
                });

            } catch (err) {
                console.error("RAG error:", err);
                await client.replyMessage({
                    replyToken: event.replyToken,
                    messages: [{ type: "text", text: "ç³»çµ±å¿™ç¢Œä¸­ï¼Œè«‹å†è©¦ä¸€æ¬¡"}],
                });
            }   
        }
    }
);

function getConversationId(source) {
    if (source.type === "user") return source.userId;
    if (source.type === "group") return source.groupId;
    if (source.type === "room") return source.roomId;
    return null;
}

/*
let openaiClient = null;

function getOpenAI() {

    if (!openaiClient) {
        openaiClient = new OpenAI({
            apiKey: process.env.OPENAI_API_KEY
        });
    }

    return openaiClient;
}
*/

// è™•ç† line webhook
/**
 * LINE webhookï¼ˆproductionï¼‰
 */

/*
router.post(
    "/",
    (req, res, next) => {
        try {
            console.log("Webhook middleware hit");
            const config = getLineConfig();
            return line.middleware(config)(req, res, next);
        } catch (err) {
            console.error("Middleware error:", err);
            return res.sendStatus(500);
        }
    },
    async (req, res) => {

        const config = getLineConfig();
        const client = new line.messagingApi.MessagingApiClient(config);
        const openai = getOpenAI();

        const events = req.body.events || [];

        for (const event of events) {
            if (event.type !== "message" || event.message.type !== "text") continue;

            const userMessage = event.message.text.trim();

            if (userMessage === "/reset") {
                await clearMemory(groupId);
                await client.replyMessage({
                    replyToken: event.replyToken,
                    messages: [{ type: "text", text: "è¨˜æ†¶å·²æ¸…é™¤"}],
                });
                continue;
            }

            try {
                const aiResponse = await getAIResponse(userMessage, openai, event.source);

                await client.replyMessage({
                    replyToken: event.replyToken,
                    messages: [
                        {
                            type: "text",
                            text: aiResponse,
                        },
                    ],
                });
            } catch (err) {
                console.error("AI error:", err);
                await client.replyMessage({
                    replyToken: event.replyToken,
                    messages: [
                        { 
                            type: "text", 
                            text: "æˆ‘å‰›å‰›æœ‰é»å¿™ï¼Œè«‹å†è©¦ä¸€æ¬¡ ğŸ™" 
                        },
                    ],
                });
            }
        }
    }
);
*/

/**
 * å–å¾—å°è©±ç´€éŒ„
 */
/*
async function loadMemory(groupId, limit = 20) {
    const docRef = db.collection(MEMORY_COLLECTION).doc(groupId);
    const doc = await docRef.get();

    if (!doc.exists()) return [];

    const messages = doc.data().messages || [];
    return messages.slice(-limit);
}
*/

/**
 * æ–°å¢ä¸€ç­†å°è©±ç´€éŒ„
 */
/*
async function appendMemory(groupId, role, content) {
    const docRef = db.collection(MEMORY_COLLECTION).doc(groupId);

    await docRef.set(
        {
            messages: admin.firestore.FieldValue.arrayUnion({
                role,
                content,
                ts: Date.now()
            }),
            updatedAt: admin.firestore.FieldValue.serverTimestamp(),
        },
        { merge: true }
    );
}
*/

/**
 * æ¸…ç©ºå°è©±ç´€éŒ„ (å¯åš /reset æŒ‡ä»¤)
 */
/*
export async function clearMemory(groupId) {
    const ref = db.collection(MEMORY_COLLECTION).doc(groupId);
    await ref.delete();
}
*/

/**
 * å‘é‡å·¥å…·
 */

/*
function dot(a, b) {
    let s = 0;
    for (let i = 0; i < a.length, i++) {
        s += a[i] * b[i];
    }
    return s;
}

function l2norm(v) {
    return Math.sqrt(dot(v, v));
}

function cosineSim(a, aNorm, b, bNorm) {
    const denom = (aNorm || l2norm(a)) * (bNorm || l2norm(b));
    if (!denom) return 0;
    return dot(a, b) / denom;
}
*/

/**
 * å„²å­˜ä¸€ç­† "å‘é‡è¨˜æ†¶"
 * @param {string} groupId userId/groupId/roomId
 * @param {object} item { text, embedding, meta }
 */

/*
export async function upsertVectorMemory(groupId, item) {
    const { text, embedding, meta = {} } = item;
    if (!text || !embedding?.length) throw new Error("Invalid vector memory item");

    const ref = db
        .collection(VECTOR_ROOT)
        .doc(groupId)
        .collection("items")
        .doc();
    
    const norm = l2norm(embedding);

    await ref.set({
        text,
        embedding,
        norm,
        meta,
        ts: Date.now(),
        updatedAt: admin.firestore.FieldValue.serverTimestamp(),
    });

    return ref.id;
}
*/

/**
 * æª¢ç´¢ç›¸ä¼¼çš„å‘é‡è¨˜æ†¶  (æƒæ conversation çš„ items)
 * @param {string} conversationId
 * @param {number[]} queryEmbedding
 * @param {number} topK
 */

/*
export async function queryVectorMemory(conversationId, queryEmebdding, topK = 5) {
    const qNorm = l2norm(queryEmbedding);

    const snap = await db
        .collection(VECTOR_ROOT)
        .doc(conversationId)
        .collection("items")
        .orderBy("ts", "desc")
        .limit(300)
        .get();
    
    const scored = [];
    snap.forEach((doc) => {
        const d = doc.data();
        if (!d.embedding?.length) return;
        const score = consineSim(queryEmbedding, qNorm, d.embedding, d.norm);
        scored.push({
            id: doc.id,
            score,
            text: d.text,
            meta: d.meta || {},
            ts: d.ts
        });
    });

    scored.sort((a, b) => b.score - a.score);
    return scored.slice(0, topK);
}
*/

/**
 * èª¿ç”¨ OpenAI ç²å– AI å›æ‡‰
 * ç•¶éœ€è¦æœå°‹è³‡æ–™æ™‚ï¼Œæœƒè‡ªå‹•ä½¿ç”¨ web_search tool
 */

/*
async function getAIResponse(userMessage, openai, source) {

    // memory æ˜¯è¨˜æ†¶çš„é™£åˆ—ï¼ŒåŒ…å«ä½¿ç”¨è€…è¨Šæ¯å’Œ AI å›æ‡‰ï¼Œå…ˆåˆå§‹åŒ–ä½¿ç”¨è€…è¨Šæ¯
    let memory = [{
        role: "user",
        content: userMessage
    }];

    const memory = await loadMemory(conversationId);

    // â‘¡ çµ„åˆ prompt
    const messages = [
      {
        role: "system",
        content:
          "ä½ æ˜¯ä¸€å€‹å‹å–„ã€å¹½é»˜ã€ä½¿ç”¨ç¹é«”ä¸­æ–‡çš„ LINE AI èŠå¤©æ©Ÿå™¨äººã€‚",
      },
      ...memory,
      { role: "user", content: userMessage },
    ];
    
    const groupId = getPushTargetFromSource(source);

    if (groupId) {
        let memory = await loadMemory(groupId, MAX_MEMORY_LENGTH);
        memory.push({ role: "user", content: userMessage });

        // æ›´æ–° memory è®Šæ•¸ç‚ºé™åˆ¶å¾Œçš„é™£åˆ—
        console.log("ç›®å‰è¨˜æ†¶:", memory);
    }

    // è¨­å®šå°ç£çš„åœ°ç†ä½ç½®è³‡è¨Šï¼ˆç”¨æ–¼ web_searchï¼‰
    const userLocation = {
        type: "approximate",
        country: "TW",
        city: "Taipei",
        region: "Taiwan",
        timezone: "Asia/Taipei"
    };

    // å‹å–„ã€å¹½é»˜çš„æç¤ºè©
    const instructions = `ä½ æ˜¯ä¸€å€‹å‹å–„ã€å¹½é»˜çš„ LINE AI èŠå¤©æ©Ÿå™¨äººåŠ©æ‰‹ã€‚ä½ çš„ç‰¹é»æ˜¯ï¼š
- å›è¦†è¦è¦ªåˆ‡ã€æº«æš–ï¼Œå°±åƒè·Ÿæœ‹å‹èŠå¤©ä¸€æ¨£
- é©åº¦ä½¿ç”¨å¹½é»˜æ„Ÿï¼Œè®“å°è©±æ›´æœ‰è¶£ï¼ˆä½†ä¸è¦å¤ªéé ­ï¼‰
- ä½¿ç”¨ç¹é«”ä¸­æ–‡å›è¦†
- å›ç­”è¦ç°¡æ½”æ˜ç­ï¼Œä¸è¦éæ–¼å†—é•·
- å¦‚æœä½¿ç”¨è€…å•åˆ°éœ€è¦æœ€æ–°è³‡è¨Šçš„å•é¡Œï¼ˆå¦‚ï¼šå¤©æ°£ã€æ–°èã€è‚¡åƒ¹ã€æ™‚äº‹ç­‰ï¼‰ï¼Œä½ æœƒè‡ªå‹•ä½¿ç”¨ç¶²è·¯æœå°‹åŠŸèƒ½ä¾†ç²å–æœ€æ–°è³‡æ–™
- ä¿æŒè¼•é¬†æ„‰å¿«çš„å°è©±æ°›åœ`;

    const response = await openai.responses.create({
        model: "gpt-4o-mini",
        instructions: instructions,
        tools: [
            {
                type: "web_search",
                user_location: userLocation
            },
        ],
        input: messages,
        include: [
            "web_search_call.action.sources"
        ],
        // æ§åˆ¶å›è¦†çš„å‰µæ„åº¦å’Œé•·åº¦
        temperature: 0.7, // ä¸­ç­‰å‰µæ„ï¼Œé©åˆå‹å–„å¹½é»˜çš„å°è©±
        max_output_tokens: 1000, // é™åˆ¶å›è¦†é•·åº¦ï¼Œä¿æŒç°¡æ½”
    });

    // æª¢æŸ¥æ˜¯å¦æœ‰ä½¿ç”¨ç¶²è·¯æœå°‹
    const hasWebSearch = response.output?.some(o => o.type === "web_search_call");
    if (hasWebSearch) {
        console.log("å·²ä½¿ç”¨ç¶²è·¯æœå°‹åŠŸèƒ½");
        const webSearchCall = response.output?.find(o => o.type === "web_search_call");
        if (webSearchCall?.action?.sources) {
            console.log("æœå°‹ä¾†æºæ•¸é‡:", webSearchCall.action.sources.length);
        }
    }

    // ä¿å­˜ AI å›æ‡‰åˆ°è¨˜æ†¶
    if (groupId) {
        memory_linebot_ai[groupId].push({
            role: "assistant",
            content: response.output_text
        });
        // é™åˆ¶è¨˜æ†¶é•·åº¦ï¼ˆåªä¿ç•™æœ€è¿‘çš„å°è©±è¨˜éŒ„ï¼‰
        memory_linebot_ai[groupId] = memory_linebot_ai[groupId].slice(-MAX_MEMORY_LENGTH);
        console.log("æ›´æ–°å¾Œçš„è¨˜æ†¶:", memory_linebot_ai[groupId]);
    }

    const aiText = response.output_text;

    await appendMemory(groupId, "user", userMessage);
    await appendMemory(groupId, "assistant", aiText);

    return aiText;
}
*/

/*
function getPushTargetFromSource(source) {
    if (source.type === "user" && source.userId) return source.userId;
    if (source.type === "group" && source.groupId) return source.groupId;
    if (source.type === "room" && source.roomId) return source.roomId;
    return undefined;
}
*/

export default router;